{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJYS8ESP+43HxxkKQmG/d2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yamenetoo/EQXGD/blob/main/ANNEQXGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def wrap_in_hash_border(text):\n",
        "    border = \"#\" * (len(text) + 4)  # Add 4 to the length for padding spaces\n",
        "    return f\"{border}\\n# {text} #\\n{border}\"\n",
        "\n",
        "\n",
        "\n",
        "# PDF of QXGD\n",
        "def dQXGD(x, theta, alpha):\n",
        "    if np.any(x < 0) or theta <= 0 or alpha <= 0:\n",
        "        raise ValueError(\"dQXGD: Invalid input: x, theta, and alpha must be greater than zero.\")\n",
        "    result = (theta / (1 + alpha)) * (alpha + (theta**2 * x**2) / 2) * np.exp(-theta * x)\n",
        "    return result\n",
        "\n",
        "# CDF of QXGD\n",
        "def pQXGD(x, theta, alpha):\n",
        "    if np.any(x < 0) or theta <= 0 or alpha <= 0:\n",
        "        raise ValueError(\"pQXGD: Invalid input: x, theta, and alpha must be greater than zero.\")\n",
        "    term1 = 1 + alpha + theta * x + (theta**2 * x**2) / 2\n",
        "    term2 = 1 + alpha\n",
        "    cdf = 1 - (term1 / term2) * np.exp(-theta * x)\n",
        "    return cdf\n",
        "\n",
        "# CDF of EQXGD\n",
        "def pEQXGD(x, theta, alpha, beta):\n",
        "    if np.any(x < 0) or theta <= 0 or alpha <= 0:\n",
        "        raise ValueError(\"pEQXGD: Invalid input: x, theta, and alpha must be greater than zero.\")\n",
        "    return pQXGD(x, theta=theta, alpha=alpha)**beta\n",
        "\n",
        "# PDF of EQXGD\n",
        "def dEQXGD(x, theta, alpha, beta):\n",
        "    if np.any(x < 0) or theta <= 0 or alpha <= 0:\n",
        "        raise ValueError(\"dEQXGD: Invalid input: x, theta, and alpha must be greater than zero.\")\n",
        "    return beta * (pQXGD(x, theta=theta, alpha=alpha)**(beta - 1)) * dQXGD(x, theta=theta, alpha=alpha)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "IRuky9t7Ocr8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text = \"Generate Data\"\n",
        "# wrapped_text = wrap_in_hash_border(text)\n",
        "# print(wrapped_text)\n"
      ],
      "metadata": {
        "id": "s1bnvBkhPvzy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "dQa4tyscNUbC",
        "outputId": "fb2e7fc4-f060-43ce-a68d-3ba521c7b180"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "f(a) and f(b) must have different signs",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-8fb96e201a8b>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtheta_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_EQXGD_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_per_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-8fb96e201a8b>\u001b[0m in \u001b[0;36mgenerate_EQXGD_data\u001b[0;34m(n_samples, n_per_sample)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mr_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_per_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mr_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrEQXGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_per_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Combine the data: r_sample will be the input (X), theta, alpha, beta will be the output (Y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-8fb96e201a8b>\u001b[0m in \u001b[0;36mrEQXGD\u001b[0;34m(n, theta, alpha, beta)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Define the root-finding function to match the quantile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpEQXGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbracket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bisect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_root_scalar.py\u001b[0m in \u001b[0;36mroot_scalar\u001b[0;34m(f, args, method, bracket, fprime, fprime2, x0, x1, xtol, rtol, maxiter, options)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbracket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethodc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;31m# gh-17622 fixed some bugs in low-level solvers by raising an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_zeros_py.py\u001b[0m in \u001b[0;36mbisect\u001b[0;34m(f, a, b, args, xtol, rtol, maxiter, full_output, disp)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"rtol too small ({rtol:g} < {_rtol:g})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrap_nan_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_zeros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bisect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bisect\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: f(a) and f(b) must have different signs"
          ]
        }
      ],
      "source": [
        "#################\n",
        "# Generate Data #\n",
        "#################\n",
        "import numpy as np\n",
        "from scipy.optimize import root_scalar\n",
        "\n",
        "def rEQXGD(n, theta, alpha, beta):\n",
        "    \"\"\"\n",
        "    Generates random samples from the EQXGD distribution using the inverse transform method.\n",
        "\n",
        "    Parameters:\n",
        "    - n: Number of samples to generate\n",
        "    - theta, alpha, beta: Parameters of the EQXGD distribution\n",
        "\n",
        "    Returns:\n",
        "    - Array of generated samples\n",
        "    \"\"\"\n",
        "    p = np.random.uniform(0, 1, n)\n",
        "    r = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        # Define the root-finding function to match the quantile\n",
        "        fn = lambda x: pEQXGD(x, theta, alpha, beta) - p[i]\n",
        "        r[i] = root_scalar(fn, bracket=[0, 100], method='bisect').root\n",
        "    return r\n",
        "\n",
        "def generate_EQXGD_data(n_samples=1000, n_per_sample=50):\n",
        "    \"\"\"\n",
        "    Generates data for training an ANN model based on the EQXGD distribution.\n",
        "\n",
        "    Parameters:\n",
        "    - n_samples: Number of sample sets to generate\n",
        "    - n_per_sample: Number of samples in each set\n",
        "\n",
        "    Returns:\n",
        "    - X: r_samples (the input data)\n",
        "    - Y: Theta, Alpha, Beta (the output parameters)\n",
        "    \"\"\"\n",
        "    # Randomly generate theta, alpha, beta values for each sample from uniform distributions\n",
        "    theta_values = np.random.uniform(0.1, 5, n_samples)  # Example range for theta\n",
        "    alpha_values = np.random.uniform(0.1, 5, n_samples)  # Example range for alpha\n",
        "    beta_values = np.random.uniform(0.1, 5, n_samples)   # Example range for beta\n",
        "    # Generate r_samples using the generated theta, alpha, beta values\n",
        "    r_samples = np.zeros((n_samples, n_per_sample))\n",
        "    for i in range(n_samples):\n",
        "        r_samples[i, :] = rEQXGD(n_per_sample, theta_values[i], alpha_values[i], beta_values[i])\n",
        "    # Combine the data: r_sample will be the input (X), theta, alpha, beta will be the output (Y)\n",
        "    X = r_samples\n",
        "    X.sort(axis=1)\n",
        "    Y = np.vstack([theta_values, alpha_values, beta_values]).T\n",
        "    return X, Y\n",
        "X,Y=generate_EQXGD_data(n_samples=10000, n_per_sample=30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def train_ann_model(X, Y, model_save_path='ann_model.h5', epochs=2000, batch_size=64, test_size=0.2, random_state=123):\n",
        "    \"\"\"\n",
        "    Train an Artificial Neural Network (ANN) model to predict parameters based on input data.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Input features, a 2D array where each row represents a sample.\n",
        "    Y (numpy.ndarray): Target output, a 2D array where each row corresponds to the parameters (theta, alpha, beta) for each sample.\n",
        "    model_save_path (str): Path to save the trained model. Default is 'ann_model.h5'.\n",
        "    epochs (int): Number of training epochs. Default is 50.\n",
        "    batch_size (int): Number of samples per gradient update. Default is 64.\n",
        "    test_size (float): Proportion of the dataset to include in the test split. Default is 0.2.\n",
        "    random_state (int): Seed for the random number generator. Default is 123.\n",
        "\n",
        "    Returns:\n",
        "    model: The trained ANN model.\n",
        "    history: Training history containing loss values and metrics over epochs.\n",
        "    predictions: Predictions made by the model on the test set.\n",
        "    actual: Actual values of theta, alpha, and beta from the test set.\n",
        "\n",
        "    Example usage:\n",
        "    model, history, predictions, actual = train_ann_model(X, Y)\n",
        "    \"\"\"\n",
        "\n",
        "    # Split the data into training and test sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Normalize the input features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Build the ANN model\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(X.shape[1],)))  # Explicit Input layer\n",
        "    model.add(Dense(128, activation='relu'))  # First hidden layer with 128 neurons\n",
        "    model.add(Dense(64, activation='relu'))   # Second hidden layer with 64 neurons\n",
        "    model.add(Dense(32, activation='relu'))   # Third hidden layer with 32 neurons\n",
        "    model.add(Dense(3, activation='relu'))     # Output layer: 3 neurons for theta, alpha, and beta\n",
        "\n",
        "    # Compile the model with Adam optimizer and mean squared error loss\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the model on the training data\n",
        "    history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss = model.evaluate(X_test, Y_test)\n",
        "    print(f\"Test loss: {test_loss}\")\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    predictions = model.predict(X_test)\n",
        "    print(f\"Predicted theta, alpha, beta: \\n{predictions[:5]}\")\n",
        "    print(f\"Actual theta, alpha, beta: \\n{Y_test[:5]}\")\n",
        "\n",
        "    # Save the trained model to the specified path\n",
        "    model.save(model_save_path)\n",
        "    print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "    return model, history, predictions, Y_test"
      ],
      "metadata": {
        "id": "J7jghpLGN1UO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wAogVAL1UAR5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}